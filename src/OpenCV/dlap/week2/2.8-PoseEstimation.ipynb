{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, sys\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../week1'))\n",
    "\n",
    "from renderFace import renderFace\n",
    "import matplotlib.pyplot as plt\n",
    "from dataPath import DATA_PATH\n",
    "from dataPath import MODEL_PATH\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0,6.0)\n",
    "matplotlib.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_FRAMES = 20\n",
    "RESIZE_HEIGHT = 320\n",
    "PREDICTOR_PATH = MODEL_PATH + \"shape_predictor_68_face_landmarks.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Model Points of selected landmarks in an \n",
    "# arbitrary frame of reference\n",
    "def get3dModelPoints():\n",
    "  modelPoints = [[0.0, 0.0, 0.0],\n",
    "                 [0.0, -330.0, -65.0],\n",
    "                 [-225.0, 170.0, -135.0],\n",
    "                 [225.0, 170.0, -135.0],\n",
    "                 [-150.0, -150.0, -125.0],\n",
    "                 [150.0, -150.0, -125.0]]\n",
    "  return np.array(modelPoints, dtype=np.float64)\n",
    "\n",
    "\n",
    "# 2D landmark points from all landmarks\n",
    "def get2dImagePoints(shape):\n",
    "  imagePoints = [[shape.part(30).x, shape.part(30).y],\n",
    "                 [shape.part(8).x, shape.part(8).y],\n",
    "                 [shape.part(36).x, shape.part(36).y],\n",
    "                 [shape.part(45).x, shape.part(45).y],\n",
    "                 [shape.part(48).x, shape.part(48).y],\n",
    "                 [shape.part(54).x, shape.part(54).y]]\n",
    "  return np.array(imagePoints, dtype=np.float64)\n",
    "\n",
    "\n",
    "# Camera Matrix from focal length and focal center\n",
    "def getCameraMatrix(focalLength, center):\n",
    "  cameraMatrix = [[focalLength, 0, center[0]],\n",
    "                  [0, focalLength, center[1]],\n",
    "                  [0, 0, 1]]\n",
    "  return np.array(cameraMatrix, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 14:00:37.441 Python[66640:3378533] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-25 14:00:37.441 Python[66640:3378533] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 69\u001b[0m\n\u001b[1;32m     63\u001b[0m newRect \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mrectangle(\u001b[38;5;28mint\u001b[39m(face\u001b[38;5;241m.\u001b[39mleft() \u001b[38;5;241m*\u001b[39m RESIZE_SCALE),\n\u001b[1;32m     64\u001b[0m                          \u001b[38;5;28mint\u001b[39m(face\u001b[38;5;241m.\u001b[39mtop() \u001b[38;5;241m*\u001b[39m RESIZE_SCALE),\n\u001b[1;32m     65\u001b[0m                          \u001b[38;5;28mint\u001b[39m(face\u001b[38;5;241m.\u001b[39mright() \u001b[38;5;241m*\u001b[39m RESIZE_SCALE),\n\u001b[1;32m     66\u001b[0m                          \u001b[38;5;28mint\u001b[39m(face\u001b[38;5;241m.\u001b[39mbottom() \u001b[38;5;241m*\u001b[39m RESIZE_SCALE))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Find face landmarks by providing reactangle for each face\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m shape \u001b[38;5;241m=\u001b[39m predictor(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m, newRect)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Draw landmarks over face\u001b[39;00m\n\u001b[1;32m     72\u001b[0m renderFace(im, shape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # Create a VideoCapture object\n",
    "  cap = cv2.VideoCapture(0)\n",
    "\n",
    "  # Check if OpenCV is able to read feed from camera\n",
    "  if (cap.isOpened() is False):\n",
    "    print(\"Unable to connect to camera\")\n",
    "    sys.exit(0)\n",
    "\n",
    "  # Just a place holder. Actual value calculated after 100 frames.\n",
    "  fps = 30.0\n",
    "\n",
    "  # Get first frame\n",
    "  ret, im = cap.read()\n",
    "\n",
    "  # We will use a fixed height image as input to face detector\n",
    "  if ret == True:\n",
    "    height = im.shape[0]\n",
    "    # calculate resize scale\n",
    "    RESIZE_SCALE = float(height)/RESIZE_HEIGHT\n",
    "    size = im.shape[0:2]\n",
    "  else:\n",
    "    print(\"Unable to read frame\")\n",
    "    sys.exit(0)\n",
    "\n",
    "  # Load face detection and pose estimation models\n",
    "  detector = dlib.get_frontal_face_detector()\n",
    "  predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "  # initiate the tickCounter\n",
    "  t = cv2.getTickCount()\n",
    "  count = 0\n",
    "\n",
    "  # Grab and process frames until the main window is closed by the user.\n",
    "  while(True):\n",
    "\n",
    "    # start tick counter if count is zero\n",
    "    if count==0:\n",
    "      t = cv2.getTickCount()\n",
    "\n",
    "    # Grab a frame\n",
    "    ret, im = cap.read()\n",
    "\n",
    "    # create imSmall by resizing image by resize scale\n",
    "    imSmall= cv2.resize(im, None, fx = 1.0/RESIZE_SCALE, fy = 1.0/RESIZE_SCALE, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    # Process frames at an interval of SKIP_FRAMES.\n",
    "    # This value should be set depending on your system hardware\n",
    "    # and camera fps.\n",
    "    # To reduce computations, this value should be increased\n",
    "    if (count % SKIP_FRAMES == 0):\n",
    "\n",
    "      # Detect faces\n",
    "      faces = detector(cv2.cvtColor(imSmall, cv2.COLOR_BGR2RGB), 0)\n",
    "\n",
    "    # get 3D model points\n",
    "    modelPoints = get3dModelPoints()\n",
    "\n",
    "    # Iterate over faces\n",
    "    for face in faces:\n",
    "      # Since we ran face detection on a resized image,\n",
    "      # we will scale up coordinates of face rectangle\n",
    "      newRect = dlib.rectangle(int(face.left() * RESIZE_SCALE),\n",
    "                               int(face.top() * RESIZE_SCALE),\n",
    "                               int(face.right() * RESIZE_SCALE),\n",
    "                               int(face.bottom() * RESIZE_SCALE))\n",
    "\n",
    "      # Find face landmarks by providing reactangle for each face\n",
    "      shape = predictor(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), newRect)\n",
    "\n",
    "      # Draw landmarks over face\n",
    "      renderFace(im, shape)\n",
    "\n",
    "      # get 2D landmarks from Dlib's shape object\n",
    "      imagePoints = get2dImagePoints(shape)\n",
    "\n",
    "      # Camera parameters\n",
    "      rows, cols, ch = im.shape\n",
    "      focalLength = cols\n",
    "      cameraMatrix = getCameraMatrix(focalLength, (rows/2, cols/2))\n",
    "\n",
    "      # Assume no lens distortion\n",
    "      distCoeffs = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "      # calculate rotation and translation vector using solvePnP\n",
    "      success, rotationVector, translationVector = cv2.solvePnP(modelPoints, imagePoints, cameraMatrix, distCoeffs)\n",
    "\n",
    "      # Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "      # We use this to draw a line sticking out of the nose\n",
    "      noseEndPoints3D = np.array([[0, 0, 1000.0]], dtype=np.float64)\n",
    "      noseEndPoint2D, jacobian = cv2.projectPoints(noseEndPoints3D, rotationVector, translationVector, cameraMatrix, distCoeffs)\n",
    "\n",
    "      # points to draw line\n",
    "      p1 = (int(imagePoints[0, 0]), int(imagePoints[0, 1]))\n",
    "      p2 = (int(noseEndPoint2D[0, 0, 0]), int(noseEndPoint2D[0, 0, 1]))\n",
    "\n",
    "      # draw line using points P1 and P2\n",
    "      cv2.line(im, p1, p2, (110, 220, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "      # Print actual FPS\n",
    "      cv2.putText(im, \"fps: {}\".format(fps), (50, size[0] - 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "\n",
    "      # Resize image for display\n",
    "      imDisplay = cv2.resize(im, None, fx=0.5, fy=0.5)\n",
    "      cv2.imshow(\"webcam Head Pose\", imDisplay)\n",
    "\n",
    "      # WaitKey slows down the runtime quite a lot\n",
    "      # So check every 15 frames\n",
    "      if (count % 15 == 0):\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Stop the program.\n",
    "        if key==27:  # ESC\n",
    "          # If ESC is pressed, exit.\n",
    "          sys.exit()\n",
    "\n",
    "      # Calculate actual fps\n",
    "      # increment frame counter\n",
    "      count = count + 1\n",
    "      # calculate fps at an interval of 100 frames\n",
    "      if (count == 100):\n",
    "        t = (cv2.getTickCount() - t)/cv2.getTickFrequency()\n",
    "        fps = 100.0/t\n",
    "        count = 0\n",
    "\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "except Exception as e:\n",
    "  print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
